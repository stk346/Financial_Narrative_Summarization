{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f980b26b",
   "metadata": {
    "id": "6Hgw3GTXLLw0"
   },
   "source": [
    "## 🤗 Finetune **Longformer Encoder-Decoder (LED)**  🤗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc65837",
   "metadata": {},
   "source": [
    "Longformer Encoder-Decoder (LED)는 최근 발표된 모델이며 트랜스 포머의 확장 버전입니다.  \n",
    "이 노트북은 Hugging Face의 Pubmed dataset으로 pre-trained된 모델의 checkpoint를 활용하여 fine-tuning을 진행합니다.  \n",
    "  \n",
    "**최소 15GB RAM 필요**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d4c5e5",
   "metadata": {},
   "source": [
    "## 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd0b19d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import rouge_score\n",
    "from rouge_score import rouge_scorer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32163c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from datasets import load_dataset, load_metric\n",
    "from transformers import (\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ded7d85",
   "metadata": {
    "id": "P59lSzY4192Z"
   },
   "outputs": [],
   "source": [
    "# 환경 설정\n",
    "\n",
    "# %%capture\n",
    "# !pip install datasets==1.2.1\n",
    "# !pip install transformers==4.2.0\n",
    "# !pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4660ab",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기  \n",
    "허깅페이스의 데이터셋 모듈을 이용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a533c3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# huggingface datasets load\n",
    "\n",
    "train_dataset = load_from_disk(\"/home/aiffelsummabot/LED/HF_train_df/\")\n",
    "val_dataset = load_from_disk(\"/home/aiffelsummabot/LED/HF_val_df/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1583374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'article': ' from outstanding performance in 2011 12, burberry began the year cautiously optimistic , our long-range objectives ensuring clarity of the luxury brand message , enabling sustainable growth and being a great company firmly in sight . angela ahrendts chief executive officer this combination of optimism and determination , fuelled by the brand’s wealth of opportunity , suggested continued pursuit of the investment-oriented strategic agenda in the year ahead . at the same time , this pre-disposition was tempered by uncertainties in the macro environment and the goal to deliver near-term financial performance . in the final analysis , the result was a balance of dynamic management , core execution and strategic investment . challenging context following standout growth in 2011 relative to the range of consumer sectors , luxury slowed dramatically in 2012. the ongoing economic crisis in the eurozone and a continued sluggish us weighed on all areas of consumer spending . although most of asia remained relatively healthy , the chinese consumer which accounts for a majority of luxury consumption growth was subdued by a secularly decelerating economy complicated by government transition . industry experts estimate that luxury sector growth declined from 13 percent in 2011 to 5 percent in 2012. within that , ready-to-wear brands and businesses were disproportionately affected . for burberry , this climate manifested itself in a decline in store traffic and greater weekly sales volatility . dynamic management internally , we talk about managing the business dynamically and focusing on the things we can control . 2012 13’s external environment tested the team on these dimensions . supported by investments in information systems and business intelligence expertise during the past few years which enable monitoring , analysis and implementation we set out to do exactly that . heightened conversion the traffic decline placed greater emphasis on converting consumers entering the stores to customers . this effort included service initiatives that maximised time on the selling floor of our most skilled associates , increased inventory availability and improved selling skills and product knowledge . in terms of product , we expedited fashion assortments targeted at core luxury customers and refined monthly floorset execution to enhance the flow of fresh merchandise . 8 chief executive officer’s letter striking the balance targeted marketing aided by deeper consumer insight , we retargeted marketing activities in keeping with changing consumer spending patterns . the team increased the brand’s presence in high-profile outdoor and travel-oriented locations and experimented with new digital venues some of which were contracted on a real-time basis . for festive periods , a cross-functional group refined programmes across product , visual and advertising to better highlight specific gift-giving opportunities . tactical efficiency the group also acted to enhance near-term efficiency . discretionary expenses were tightly controlled and inventory was closely managed at all stages of the process in keeping with softer sales . core execution articulated by the five strategic themes , burberry’s core strategy has been consistently executed over the past seven years , and actions to navigate immediate conditions did not sway us from this course . blurring the physical and digital given a world of increasingly ubiquitous mobile internet access , we expect dissolution of the boundaries separating physical and digital channels . consumers will see a single , continuous space in which to interact with a brand . through a range of activities , we are working to integrate the benefits of the physical and digital spheres . ultimately , the vision is to serve completely any consumer on any platform in any geography . in this regard , the opening of the london flagship at 121 regent street in september is our most ambitious effort to date . housed in a period building restored in partnership with traditional british craftsmen , the store expresses burberry .com in tangible space complete product assortment , rfid technology to trigger targeted multimedia content , omnipresent digital screens continuously projecting brand imagery . burberry world live , a store of the future , blending heritage and innovation , online with offline . additional integration initiatives included the expanded use of ipads to enhance inventory availability , continued upgrading of retail theatre throughout the store base to ensure synchronised delivery of brand content to consumers , and experimentation with new payment systems to streamline the purchase experience . enhancing the product proposition at the heart of the burberry brand , product was a key area of strategic activity . elevation of the product offering is an ongoing process . in the year , we exited selected opening price points in heritage rainwear and leather goods categories . exacting a cost in terms of sales , this is consistent with the brand’s positioning within the current luxury context . similarly responding to consumer demand , we continued to invest in the upper tiers of our product pyramid , the prorsum and london labels . these labels increased their share of retail sales during the year . although founded as a mens brand , burberry is underpenetrated in mens . during the year , outerwear benefited from greater emphasis on innovation and design . tailoring developed with broader assortments and expanded distribution . closer attention to in-store timing of seasonal merchandise enhanced relevance of the offering . and the first fully dedicated burberry mens store was opened in london in october 2012. achieving a 13 percent revenue increase , mens was the fastest growing product division in the year . with mens integration only two years old , burberry is in the early stages of capitalising on this heritage . october saw the launch of the britain watch for women and men . the britain , featuring an advanced swiss-made mechanical movement and more sophisticated design , is an important step in realigning burberry’s watch business with the brand’s luxury positioning . engaging the chinese consumer globally given their importance , efforts to better understand and serve chinese consumers are an ongoing priority . during the year , burberry conducted proprietary research , leveraging the results across functions to extend product sizing and fit , to train sales associates in high-travel markets , to formulate occasion-specific marketing campaigns citing a few examples . in the year , greater china represented burberry’s fastest growing major market and this consumer was prominent throughout the retail network . 9 chief executive officer’s letter developing growth markets outside asia , the group continued to develop other growth markets . in the directly operated markets of india , latin america and the middle east , the group opened net six mainline stores during the year . while some offer below average profitability today , we believe these markets represent important components of future growth . in regions operated through franchise partners , including turkey , russia and eastern europe , eight stores were opened with expansion to five new markets , including georgia and jordan . new franchise agreements were signed for colombia and chile . expanding the retail presence in addition to london , the year included flagship store openings in chicago , hong kong and milan . while contributing to sales , these brand statements in gateway cities present the complete burberry to diverse groups of relevant consumers , many of them new to the brand . in total , the group opened net 14 mainline stores , six concessions and five outlets during the year , and completed seven major renovations . average selling space increased 13 percent . refining the wholesale presence efforts to align the quality of the brand’s wholesale presence with that of retail are ongoing . in both the americas and europe , we continued to concentrate on luxury-oriented department and specialty stores with emphasis on dedicated real estate while exiting legacy doors inconsistent with the brand’s positioning . this activity , in combination with the channel’s exposure to soft geographies , resulted in 1 percent underlying wholesale revenue growth for the year . as part of the brand proposition , burberry looks to be a leader in consumers’ digital interaction with brands , in both innovation and capability . in marketing , the s s13 campaign generated record awareness through social media . total burberry youtube video views reached over ten million during the year . rfid-enabled personalised content was introduced with the a w13 runway show . experimenting with emerging digital platforms , burberry streamed live images of london weather to prominent outdoor sites in london , paris , hong kong , los angeles and new york during the olympic period . in commerce , burberry .com added spanish and korean languages and tested new fulfilment options . strategic investment while executing currently , the team invested in strategic initiatives with longer-term horizons . integrating beauty among the most exciting strategic investments in recent years , the transition of burberry’s fragrance and make-up business from a licensed to a directly operated business began in the year . offering luxury’s opening price point and broadest distribution , fragrance is the most widely encountered expression of the burberry brand . the category also accounts for a large percentage of global brand media spend . as a result , direct operation will assist in optimising brand presence in every market , further enable burberry to capitalise on the synergistic relationship with fashion , and better align the product offering with brand architecture . integration elevates this business to true core activity , allowing burberry to capture the full opportunity . in terms of opportunity , despite burberry’s position among the largest luxury apparel and accessories brands globally , it is undersized in fragrance . growth has been slow , with fragrance significantly underperforming the rest of the group over the past five years . in make-up , the brand has only just started . from the decision to integrate in october , the team moved quickly across functions , leveraging existing skills and resources while adding external category-specific talent and capability . as of 1 april , beauty had been successfully integrated and commenced operating . burberry’s fifth product division , beauty is a growth platform of the future . evolving customer dialogue in a landscape of big data and continuous communication , we believe information-intensive , deep customer relationships which allow an individualised customer dialogue will be critical to future success in luxury . as part of this , the group began developing new tools to provide an integrated view of a customer’s interaction with the brand across all burberry platforms , with initial piloting of a clienteling application commencing at year end . development work to enhance consumers’ ability to engage the brand through mobile devices also progressed in the year . 10 chief executive officer’s letter transitioning the japan legacy in japan , transition from the legacy licensed business to global integration continued . as part of this , burberry’s early stage retail operation achieved strong growth at existing stores and concessions , opened a concession , added a third store and planned additional openings in 2013 14 while the effect of licence terminations continued to reduce legacy royalty income . reinforcing the supply chain to accommodate future growth objectives , the group reinforced the supply chain . in logistics , burberry added distribution capacity , upgraded existing facilities and increased network efficiency . in sourcing , additional resources were committed to further develop in-house outerwear manufacturing capability and improve raw material management . strong financial results this balance of activity delivered record financial results in 2012 13 while positioning burberry well for years ahead . total revenue increased 8 percent underlying to pound 2bn . retail revenue grew 12 percent driven by new space and a 5 percent comparable store gain . soft european markets particularly weighed on wholesale , resulting in a 1 percent underlying revenue increase . the 1 percent underlying decline in licensing revenue was a product of double-digit growth among global licences more than offset by declining legacy japan royalties . adjusted operating profit increased 14 percent to pound 428m , with the core retail wholesale segment increasing 17 percent on 8 percent revenue growth retail wholesale operating margin also reached a record 17.8 percent . capital expenditure totalled pound 176m and the group ended the year with pound 297m in net cash . powerful culture burberry’s culture is a key ingredient to this success . rooted in the brand’s core values and fuelled by a creative-thinking , entrepreneurial spirit , our connected , united culture creates an energy that enables innovation , coordination and agility . these characteristics are evident in the year’s accomplishments . this distinctive culture is also expressed externally through ethical trade and sustainability efforts , employee engagement with local communities and the burberry foundation , which contributes both human and capital resources to encourage youth to realise their dreams through the power of creativity . we continued to invest in this powerful culture throughout the organisation communication initiatives , operating structures , reward programmes and celebrations . the bigger the business becomes , the more connected we will need to be . a great community through the efforts of this great team we largely realised our objectives . so i thank them , as well as burberry’s extended community of franchise and licensing partners , customers and suppliers , for their passion , commitment and hard work during the year . looking forward , this team provides confidence for markets favourable or not . kpi growth in adjusted diluted eps year to 31 march is a key valuation metric for burberry’s shareholders . 70.0p 14 percent 2013 2012 2011 2010 2009 70.0 14 percent 61.6 26 percent 48.9 39 percent 35.1 16 percent 30.2 -4 percent adjusted diluted eps is stated before exceptional items . reported diluted eps 57.0p 2012 59.3p . 11 chief executive officer’s letter ',\n",
       " 'abstract': 'from outstanding performance in 2011 12, burberry began the year cautiously optimistic , our long-range objectives ensuring clarity of the luxury brand message , enabling sustainable growth and being a great company firmly in sight .angela ahrendts chief executive officer this combination of optimism and determination , fuelled by the brand’s wealth of opportunity , suggested continued pursuit of the investment-oriented strategic agenda in the year ahead .at the same time , this pre-disposition was tempered by uncertainties in the macro environment and the goal to deliver near-term financial performance .in the final analysis , the result was a balance of dynamic management , core execution and strategic investment .challenging context following standout growth in 2011 relative to the range of consumer sectors , luxury slowed dramatically in 2012. the ongoing economic crisis in the eurozone and a continued sluggish us weighed on all areas of consumer spending .although most of asia remained relatively healthy , the chinese consumer which accounts for a majority of luxury consumption growth was subdued by a secularly decelerating economy complicated by government transition .industry experts estimate that luxury sector growth declined from 13 percent in 2011 to 5 percent in 2012. within that , ready-to-wear brands and businesses were disproportionately affected .additional integration initiatives included the expanded use of ipads to enhance inventory availability , continued upgrading of retail theatre throughout the store base to ensure synchronised delivery of brand content to consumers , and experimentation with new payment systems to streamline the purchase experience .and the first fully dedicated burberry mens store was opened in london in october 2012. achieving a 13 percent revenue increase , mens was the fastest growing product division in the year .strategic investment while executing currently , the team invested in strategic initiatives with longer-term horizons .soft european markets particularly weighed on wholesale , resulting in a 1 percent underlying revenue increase .capital expenditure totalled pound 176m and the group ended the year with pound 297m in net cash .',\n",
       " '__index_level_0__': 1592}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe607ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['__index_level_0__', 'abstract', 'article'],\n",
       "    num_rows: 2445\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac56d9d",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb41e5f3",
   "metadata": {},
   "source": [
    "데이터셋을 매핑하고 가공하는 함수 코드를 작성합니다.  \n",
    "**article**은 input 데이터를 나타냅니다.  \n",
    "**abstract**는 target 데이터입니다.  \n",
    "`mex_len`은 4096으로 설정하며 `max token`은 512, `batch_size`는 1로 설정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afc0c42",
   "metadata": {},
   "source": [
    "LED의 `global_attention_mask`는 어떤 입력 토큰의 전역적인(global) 적용과 지역적인(local) 적용을 정의할 수 있습니다.  \n",
    "대략적인 사항은 논문에 나와 있으며 첫 번째 토큰에만 global attention을 적용합니다. 인덱스를 -100으로 설정하는 것은 패딩된 토큰에 대해 loss가 계산되는 것을 차단하기 위함입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19146d6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sMQWD3wL192Z",
    "outputId": "80096c0e-b26b-488f-ac55-d194e2579d2f"
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-base-16384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62abf2ee",
   "metadata": {
    "id": "jk7tS_xN192b"
   },
   "outputs": [],
   "source": [
    "max_input_length = 4096\n",
    "max_output_length = 512\n",
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70b28121",
   "metadata": {
    "id": "2_UzG6Ek192b"
   },
   "outputs": [],
   "source": [
    "def process_data_to_model_inputs(batch):\n",
    "    # tokenize the inputs and labels\n",
    "    inputs = tokenizer(\n",
    "        batch[\"article\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_input_length,\n",
    "    )\n",
    "    outputs = tokenizer(\n",
    "        batch[\"abstract\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_output_length,\n",
    "    )\n",
    "\n",
    "    batch[\"input_ids\"] = inputs.input_ids\n",
    "    batch[\"attention_mask\"] = inputs.attention_mask\n",
    "\n",
    "    # create 0 global_attention_mask lists\n",
    "    batch[\"global_attention_mask\"] = len(batch[\"input_ids\"]) * [\n",
    "        [0 for _ in range(len(batch[\"input_ids\"][0]))]\n",
    "    ]\n",
    "\n",
    "    # since above lists are references, the following line changes the 0 index for all samples\n",
    "    batch[\"global_attention_mask\"][0][0] = 1\n",
    "    batch[\"labels\"] = outputs.input_ids\n",
    "\n",
    "    # We have to make sure that the PAD token is ignored\n",
    "    batch[\"labels\"] = [\n",
    "        [-100 if token == tokenizer.pad_token_id else token for token in labels]\n",
    "        for labels in batch[\"labels\"]\n",
    "    ]\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cfbc16",
   "metadata": {},
   "source": [
    "위에서 정의한 함수에 데이터셋을 매핑합니다. 토크나이징까지 완료 됐으므로 기존의 컬럼은 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3971ec4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "a7fe6f9ae61b4cfbadaba2c0bfc50e1a",
      "f3b8ce93ce314a4d80b6e7b9f935600c",
      "58609f6a301741c788d9e190e49601bc",
      "727b33b4d0ba48d3be3b76040bfb0ead",
      "ea44f4c51d334e3aa3ed03acbb795242",
      "591785faa90742dfb12a3436c2dee0e2",
      "8156f721d27246b5a5357fac577b7d82",
      "415c082418fd4c3b94408e00bbcda82a"
     ]
    },
    "id": "wcaN0IJD192b",
    "outputId": "952499e3-265a-4694-ec89-7f848d19f2a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "572329cf3b67462484992efa981efc84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1223.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"article\", \"abstract\", \"__index_level_0__\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f650bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "aa16af7563554384be6e5513c6afe79a",
      "3eb2a25aab6141bfa1cf5a76bed6c5b2",
      "be015dcb6cef4b41911e69fbc5af1a59",
      "a62d68c2e4914f0ba08ede851cf47280",
      "f2c219f0099d411caf4ff5e831673875",
      "0e6d376e4a394a2aa025e2edc3898ec8",
      "628aa2531c944e4e8efeecf6fca40993",
      "78482e48010a412385fbe008d146d728"
     ]
    },
    "id": "FkrEujTX192b",
    "outputId": "56576f0b-29df-4fde-84e5-c82f81de6b81"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafe50ad94dd4a228887e59092315a99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=136.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "val_dataset = val_dataset.map(\n",
    "    process_data_to_model_inputs,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    remove_columns=[\"article\", \"abstract\", \"__index_level_0__\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221e3997",
   "metadata": {
    "id": "abdbZ4eW192b"
   },
   "source": [
    "데이터셋이 다음과 같은 형태로 변환됐습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a15a2e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['attention_mask', 'global_attention_mask', 'input_ids', 'labels'],\n",
       "    num_rows: 2445\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab689cf",
   "metadata": {},
   "source": [
    "파이토치를 이용해 모델링을 진행할 것이므로 파이토치의 format으로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd6b651",
   "metadata": {
    "id": "fC9arodU192b"
   },
   "outputs": [],
   "source": [
    "train_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")\n",
    "val_dataset.set_format(\n",
    "    type=\"torch\",\n",
    "    columns=[\"input_ids\", \"attention_mask\", \"global_attention_mask\", \"labels\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b245fe",
   "metadata": {
    "id": "A4j2pUM_192c"
   },
   "source": [
    "`AutoModelForSeq2SeqLM` 클래스를 이용해 모델을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09e5d609",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "642d8f4c64474cccbec943413240c027",
      "d2ad50bf2a3b4b77947a29b72ec2bc8c",
      "2dcf5d79460d4554940dd259ccca44a4",
      "1960516a36a3417c8a3c345d2cc101ec",
      "519ced1cfc774ca2a671cfe3903623a8",
      "2074f2221bef4523ba6f7364db39651c",
      "b395732993124de480c2da0b8bb63032",
      "f2e83c9cec9b4236afb6a7227ebf5db9"
     ]
    },
    "id": "vHw7_nMQ192c",
    "outputId": "38090c2b-bfad-4469-cf87-613f75634229"
   },
   "outputs": [],
   "source": [
    "led = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/led-base-16384\", gradient_checkpointing=True, use_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973206f",
   "metadata": {},
   "source": [
    "train을 진행하는 동안 Rouge 스코어를 통해 모델을 평가합니다. 이로써 모델의 학습이 잘 되는지 확인할 수 있습니다. beam search를 통해 메모리를 절약합니다.  \n",
    "`max_length`=100, `min_length`=512로 설정했으므로 100~512개의 토큰이 만들어질 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0a0009",
   "metadata": {
    "id": "vSt8x6mu192c"
   },
   "outputs": [],
   "source": [
    "# set generate hyperparameters\n",
    "led.config.num_beams = 2\n",
    "led.config.max_length = 512\n",
    "led.config.min_length = 100\n",
    "led.config.length_penalty = 2.0\n",
    "led.config.early_stopping = True\n",
    "led.config.no_repeat_ngram_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac749d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "5e605dd890d741a5a89dd1fd04183e9c",
      "b7bfd05045ef495bad3d30e6a2ad3f9b",
      "dea7c32f1e71438d9e30d808be8ff585",
      "8d22ef0d5edb458781eccf7e0037cbcd",
      "20c130370f4249a68c2a73fc4369f527",
      "d94589c558cf4f928bfdbfc1c182c806",
      "f177d781255f4db783b7394229d8f730",
      "fc1e239059a945139662bc1dd6b0b2b5"
     ]
    },
    "id": "B1gU2BXJ192c",
    "outputId": "eade9532-4546-4359-b29f-599916726da5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rouge = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28167eba",
   "metadata": {},
   "source": [
    "`compute_metrics` 함수는  label과 output(predict)에 대한 인덱스를 얻은 뒤 이를 decode 합니다. 이후 이에 대한 rouge 스코어를 계산합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bf8c935",
   "metadata": {
    "id": "z9o3v3O9192c"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    rouge_output = rouge.compute(\n",
    "        predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"]\n",
    "    )[\"rouge2\"].mid\n",
    "\n",
    "    return {\n",
    "        \"rouge2_precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2_recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2_fmeasure\": round(rouge_output.fmeasure, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9c5b8",
   "metadata": {
    "id": "WSUZxqMX192d"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a2eef2",
   "metadata": {},
   "source": [
    "`Seq2SeqTrainer`에서 `predict_with_generate=True`로 설정하면 evaluation이 진행되는 도중에 `generate()`가 시행됩니다.\n",
    "`gradient_accumulation_steps`를 높이면 GPU RAM을 효과적으로 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8236db2f",
   "metadata": {
    "id": "s9TBR1Fa192d"
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    fp16=False,\n",
    "    output_dir=\"/home/aiffelsummabot/LED/\",\n",
    "    logging_steps=5,\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    save_total_limit=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90a8ab2",
   "metadata": {},
   "source": [
    "앞에서 정의했던 model, tokenizer, datasets, `compute_metrics` 함수를 `Seq2SeqTrainer`에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e8a490",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5aba0e45",
   "metadata": {
    "id": "BVddmiYv192d"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=led,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a156a574",
   "metadata": {
    "id": "CigrFIc4192d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msummabot\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/summabot/huggingface/runs/1gi8i579\" target=\"_blank\">/home/aiffelsummabot/LED/</a></strong> to <a href=\"https://wandb.ai/summabot/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffelsummabot/anaconda3/envs/summabot/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='2' max='153' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  2/153 : < :, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11363/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/summabot/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    886\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m                     \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/summabot/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_wrapped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/summabot/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/summabot/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a057d4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb486aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_from_disk(\"/home/aiffelsummabot/LED/HF_test_df/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c1950",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedcfd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
    "\n",
    "pubmed_test = test_dataset\n",
    "\n",
    "# 체크포인트 로드\n",
    "model_path = \"/home/aiffelsummabot/LED/checkpoint-500/\"\n",
    "tokenizer = LEDTokenizer.from_pretrained(model_path)\n",
    "model = LEDForConditionalGeneration.from_pretrained(model_path).to(\"cuda\").half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae312908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(batch):\n",
    "    inputs_dict = tokenizer(batch[\"article\"], padding=\"max_length\", max_length=4096, return_tensors=\"pt\", truncation=True)\n",
    "    input_ids = inputs_dict.input_ids.to(\"cuda\")\n",
    "    attention_mask = inputs_dict.attention_mask.to(\"cuda\")\n",
    "    global_attention_mask = torch.zeros_like(attention_mask)\n",
    "    # put global attention on <s> token\n",
    "    global_attention_mask[:, 0] = 1\n",
    "\n",
    "    predicted_abstract_ids = model.generate(input_ids, attention_mask=attention_mask, global_attention_mask=global_attention_mask)\n",
    "    batch[\"predicted_abstract\"] = tokenizer.batch_decode(predicted_abstract_ids, skip_special_tokens=True)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469d0584",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "result = pubmed_test.map(generate_answer, batched=True, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b17aae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load rouge\n",
    "rouge = load_metric(\"rouge\")\n",
    "\n",
    "print(\"Result:\", rouge.compute(predictions=result[\"predicted_abstract\"], references=result[\"abstract\"], rouge_types=[\"rouge2\"])[\"rouge2\"].mid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ae79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1598c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_result = pd.DataFrame({'abstract': result['abstract'],\n",
    "                                                    'article': result['article'],\n",
    "                                                    'predicted_abstract': result['predicted_abstract']})\n",
    "\n",
    "predicted_result.to_csv('./predicted_document.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acec456",
   "metadata": {},
   "source": [
    "#### prediction file 가져오기\n",
    "Pegasus와 비교하기 위해 처음 100개의 text열을 따로 prediction_df2로 지정하고 Pegasus model 과 같은 rouge score (rouge1, rougeL - f-measure)를 계산해줬다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6d3f448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>article</th>\n",
       "      <th>predicted_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s .c .h...</td>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ...</td>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s.c.har...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strategic report chief executive’s statement 1...</td>\n",
       "      <td>strategic report chief executive’s statement ...</td>\n",
       "      <td>strategic report chief executive’s statement 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summary our dedication to providing our client...</td>\n",
       "      <td>summary our dedication to providing our clien...</td>\n",
       "      <td>summary our dedication to providing our client...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q a with ceo , david miles 92 percent of tenan...</td>\n",
       "      <td>q a with ceo , david miles 92 percent of tena...</td>\n",
       "      <td>q a with ceo, david miles 92 percent of tenant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in the spring , we launched our walk in wins’ ...</td>\n",
       "      <td>strategic report domino’s pizza group plc ann...</td>\n",
       "      <td>strategy across all of our markets remains sim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            abstract  \\\n",
       "0  25695 19 march 2018 3 29 pm proof 7 02 s .c .h...   \n",
       "1  strategic report chief executive’s statement 1...   \n",
       "2  summary our dedication to providing our client...   \n",
       "3  q a with ceo , david miles 92 percent of tenan...   \n",
       "4  in the spring , we launched our walk in wins’ ...   \n",
       "\n",
       "                                             article  \\\n",
       "0   25695 19 march 2018 3 29 pm proof 7 02 s . c ...   \n",
       "1   strategic report chief executive’s statement ...   \n",
       "2   summary our dedication to providing our clien...   \n",
       "3   q a with ceo , david miles 92 percent of tena...   \n",
       "4   strategic report domino’s pizza group plc ann...   \n",
       "\n",
       "                                  predicted_abstract  \n",
       "0  25695 19 march 2018 3 29 pm proof 7 02 s.c.har...  \n",
       "1  strategic report chief executive’s statement 1...  \n",
       "2  summary our dedication to providing our client...  \n",
       "3  q a with ceo, david miles 92 percent of tenant...  \n",
       "4  strategy across all of our markets remains sim...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "prediction_df = pd.read_csv('./predicted_document.csv', index_col=0)\n",
    "prediction_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e81188a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_df2 = prediction_df[:100].copy()\n",
    "len(prediction_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81a040",
   "metadata": {},
   "source": [
    "#### rouge score 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bcaac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rouge_scores(gen_summary_list, actual_summary_list, metric='fmeasure'):\n",
    "    rouge1_scores = []\n",
    "    rougeL_scores = []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    for i in range(0, len(gen_summary_list)):\n",
    "        scores = scorer.score(actual_summary_list[i], gen_summary_list[i])\n",
    "        if metric == 'recall':\n",
    "            rouge1_scores.append(scores['rouge1'][1])\n",
    "            rougeL_scores.append(scores['rougeL'][1])\n",
    "        elif metric == 'precision':\n",
    "            rouge1_scores.append(scores['rouge1'][0])\n",
    "            rougeL_scores.append(scores['rougeL'][0])\n",
    "        elif metric == 'fmeasure':\n",
    "            rouge1_scores.append(scores['rouge1'][2])\n",
    "            rougeL_scores.append(scores['rougeL'][2])     \n",
    "    print(\"Average Rouge-1\", str(metric), \":\", round(np.mean(rouge1_scores), 2))\n",
    "    print(\"Average Rouge-L\", str(metric), \":\", round(np.mean(rougeL_scores), 2))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eaaf7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rouge-1 fmeasure : 0.54\n",
      "Average Rouge-L fmeasure : 0.39\n"
     ]
    }
   ],
   "source": [
    "rouge_scores(prediction_df2['predicted_abstract'], prediction_df['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f388dd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
