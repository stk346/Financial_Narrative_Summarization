{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pegasus Fine Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import cuda\n",
    "device = torch.device(\"cuda\") #if torch.cuda.is_available() else \"cpu\")\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sBR54RA_Vjhf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from transformers import PegasusTokenizer, PegasusForConditionalGeneration\n",
    "\n",
    "# WandB – Import the wandb library\n",
    "import wandb\n",
    "import time\n",
    "from rouge_score import rouge_scorer\n",
    "import shap\n",
    "import sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = '/home/aiffelsummabot/Pegasus/finetuned_model'\n",
    "\n",
    "predictions_filepath = '/home/aiffelsummabot/Pegasus/predictions/pegasus_predictions.csv'\n",
    "\n",
    "wandb_project_name = \"pegasus\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>FT_Len</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15783_819108_2</td>\n",
       "      <td>chief executive officer’s statement the berong...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>the berong nickel mine has been in operation f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15782_819091_2</td>\n",
       "      <td>chief executive officer’s statement the compan...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>berong nickel corporation is setting new stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15787_819176_2</td>\n",
       "      <td>page 6 toledo mining corporation plc annual re...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>toledo mining corporation plc reported a pre-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15819_820208_2</td>\n",
       "      <td>review 2005 chief executive’s statement tomkin...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>a key component of this is new product develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15842_821001_2</td>\n",
       "      <td>7 plc annual report and financial statements 2...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>topps has seen its position as the uk’s number...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original_Filename                                          Full_Text  \\\n",
       "0    15783_819108_2  chief executive officer’s statement the berong...   \n",
       "1    15782_819091_2  chief executive officer’s statement the compan...   \n",
       "2    15787_819176_2  page 6 toledo mining corporation plc annual re...   \n",
       "3    15819_820208_2  review 2005 chief executive’s statement tomkin...   \n",
       "4    15842_821001_2  7 plc annual report and financial statements 2...   \n",
       "\n",
       "   FT_Len                                            Summary  \n",
       "0   500.0  the berong nickel mine has been in operation f...  \n",
       "1   500.0  berong nickel corporation is setting new stand...  \n",
       "2   500.0  toledo mining corporation plc reported a pre-t...  \n",
       "3   500.0  a key component of this is new product develop...  \n",
       "4   500.0  topps has seen its position as the uk’s number...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = 'train_data_final.csv'\n",
    "\n",
    "train_df = pd.read_csv(filepath, index_col=0)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>FT_Len</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15783_819108_2</td>\n",
       "      <td>chief executive officer’s statement the berong...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>the berong nickel mine has been in operation f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15782_819091_2</td>\n",
       "      <td>chief executive officer’s statement the compan...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>berong nickel corporation is setting new stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15787_819176_2</td>\n",
       "      <td>page 6 toledo mining corporation plc annual re...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>toledo mining corporation plc reported a pre-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15819_820208_2</td>\n",
       "      <td>review 2005 chief executive’s statement tomkin...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>a key component of this is new product develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15842_821001_2</td>\n",
       "      <td>7 plc annual report and financial statements 2...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>topps has seen its position as the uk’s number...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original_Filename                                          Full_Text  \\\n",
       "0    15783_819108_2  chief executive officer’s statement the berong...   \n",
       "1    15782_819091_2  chief executive officer’s statement the compan...   \n",
       "2    15787_819176_2  page 6 toledo mining corporation plc annual re...   \n",
       "3    15819_820208_2  review 2005 chief executive’s statement tomkin...   \n",
       "4    15842_821001_2  7 plc annual report and financial statements 2...   \n",
       "\n",
       "   FT_Len                                            Summary  \n",
       "0   500.0  the berong nickel mine has been in operation f...  \n",
       "1   500.0  berong nickel corporation is setting new stand...  \n",
       "2   500.0  toledo mining corporation plc reported a pre-t...  \n",
       "3   500.0  a key component of this is new product develop...  \n",
       "4   500.0  topps has seen its position as the uk’s number...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 짧은 데이터 제거해주기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['FT_Len'].hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    11954.000000\n",
       "mean       444.643299\n",
       "std        123.898723\n",
       "min          1.000000\n",
       "25%        500.000000\n",
       "50%        500.000000\n",
       "75%        500.000000\n",
       "max        500.000000\n",
       "Name: FT_Len, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['FT_Len'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>FT_Len</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>15819_820208_2</td>\n",
       "      <td>of our cost of capital in the years ahead . ne...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>nicol's businesses are focused on creating sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2749</th>\n",
       "      <td>16184_838031_2</td>\n",
       "      <td>principle , to the economic uncertainties that...</td>\n",
       "      <td>163.0</td>\n",
       "      <td>to the economic uncertainties that our custome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2771</th>\n",
       "      <td>16367_846240_2</td>\n",
       "      <td>. this order was completed in february 2012 an...</td>\n",
       "      <td>184.0</td>\n",
       "      <td>in march 2012, we announced that ge aviation p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>16497_853744_2</td>\n",
       "      <td>the continuing development of the geneice plat...</td>\n",
       "      <td>109.0</td>\n",
       "      <td>dr satu vainikka chief executive officer val20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2810</th>\n",
       "      <td>16717_862599_2</td>\n",
       "      <td>to fill our new capacity with a diverse mix of...</td>\n",
       "      <td>130.0</td>\n",
       "      <td>victrex will continue to provide a clear point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11920</th>\n",
       "      <td>7194_368643_2</td>\n",
       "      <td>specific market sectors to take full advantage...</td>\n",
       "      <td>93.0</td>\n",
       "      <td>tony brewer group chief executive uk deliverie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11923</th>\n",
       "      <td>7309_378031_2</td>\n",
       "      <td>appraisal activities and approximately dollar ...</td>\n",
       "      <td>107.0</td>\n",
       "      <td>, we invest approximately dollar 55 million to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11936</th>\n",
       "      <td>150_6208_2</td>\n",
       "      <td>of a target in half the time taken previously ...</td>\n",
       "      <td>173.0</td>\n",
       "      <td>jonathan milner ceo 8 september 2008. since th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11939</th>\n",
       "      <td>169_12459_2</td>\n",
       "      <td>of server failure in the evening or at weekend...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>acal it solutions offered expert knowledge to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11947</th>\n",
       "      <td>325_19926_2</td>\n",
       "      <td>saas subscription revenue relates to advanced ...</td>\n",
       "      <td>29.0</td>\n",
       "      <td>. 5 percent including csh and csh-based servic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1057 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Original_Filename                                          Full_Text  \\\n",
       "2720     15819_820208_2  of our cost of capital in the years ahead . ne...   \n",
       "2749     16184_838031_2  principle , to the economic uncertainties that...   \n",
       "2771     16367_846240_2  . this order was completed in february 2012 an...   \n",
       "2790     16497_853744_2  the continuing development of the geneice plat...   \n",
       "2810     16717_862599_2  to fill our new capacity with a diverse mix of...   \n",
       "...                 ...                                                ...   \n",
       "11920     7194_368643_2  specific market sectors to take full advantage...   \n",
       "11923     7309_378031_2  appraisal activities and approximately dollar ...   \n",
       "11936        150_6208_2  of a target in half the time taken previously ...   \n",
       "11939       169_12459_2  of server failure in the evening or at weekend...   \n",
       "11947       325_19926_2  saas subscription revenue relates to advanced ...   \n",
       "\n",
       "       FT_Len                                            Summary  \n",
       "2720     53.0  nicol's businesses are focused on creating sha...  \n",
       "2749    163.0  to the economic uncertainties that our custome...  \n",
       "2771    184.0  in march 2012, we announced that ge aviation p...  \n",
       "2790    109.0  dr satu vainikka chief executive officer val20...  \n",
       "2810    130.0  victrex will continue to provide a clear point...  \n",
       "...       ...                                                ...  \n",
       "11920    93.0  tony brewer group chief executive uk deliverie...  \n",
       "11923   107.0  , we invest approximately dollar 55 million to...  \n",
       "11936   173.0  jonathan milner ceo 8 september 2008. since th...  \n",
       "11939    67.0  acal it solutions offered expert knowledge to ...  \n",
       "11947    29.0  . 5 percent including csh and csh-based servic...  \n",
       "\n",
       "[1057 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[train_df['FT_Len'] < 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FT_Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10897.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>478.069193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>62.372498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             FT_Len\n",
       "count  10897.000000\n",
       "mean     478.069193\n",
       "std       62.372498\n",
       "min      200.000000\n",
       "25%      500.000000\n",
       "50%      500.000000\n",
       "75%      500.000000\n",
       "max      500.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3 = train_df.loc[train_df['FT_Len'] >= 200].copy()\n",
    "train_df3.reset_index(drop=True, inplace=True)\n",
    "train_df3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "rVKgosXtWLmB"
   },
   "outputs": [],
   "source": [
    "# Creating a custom dataset for reading the dataframe and loading it into the dataloader to pass it to the neural network at a later stage for finetuning the model and to prepare it for predictions\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.Summary\n",
    "        self.ctext = self.data.Full_Text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        # input\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length= self.source_len, \n",
    "                                                  pad_to_max_length=True,\n",
    "                                                  return_tensors='pt',\n",
    "                                                  truncation=True)\n",
    "        \n",
    "        # label\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length= self.summ_len, \n",
    "                                                  pad_to_max_length=True,\n",
    "                                                  return_tensors='pt',\n",
    "                                                  truncation=True)\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze()\n",
    "        source_mask = source['attention_mask'].squeeze()\n",
    "        target_ids = target['input_ids'].squeeze()\n",
    "        target_mask = target['attention_mask'].squeeze()\n",
    "\n",
    "        return {\n",
    "            'source_ids': source_ids.to(dtype=torch.long), \n",
    "            'source_mask': source_mask.to(dtype=torch.long), \n",
    "            'target_ids': target_ids.to(dtype=torch.long),\n",
    "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2YSAgJuzW555"
   },
   "outputs": [],
   "source": [
    "def train(epoch, tokenizer, model, loader, optimizer): # device\n",
    "    model.train()\n",
    "    for _,data in enumerate(loader, 0):\n",
    "        # Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu\n",
    "        # => You need to add your data to the same device as your model.\n",
    "        y = data['target_ids'].to(device, dtype = torch.long)\n",
    "        y_ids = y[:, :-1].contiguous()\n",
    "        lm_labels = y[:, 1:].clone().detach()\n",
    "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
    "        ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "        mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "        \n",
    "        # Changed this code from lm_labels to labels; lm_labels is deprecated - https://github.com/priya-dwivedi/Deep-Learning/issues/137\n",
    "        # outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "        outputs = model(input_ids = ids, attention_mask = mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
    "        loss = outputs[0]\n",
    "        \n",
    "       # if _%10 == 0:\n",
    "            # print(torch.cat(loss.item(), 0))\n",
    "            #torch.cat(loss.item(), 0)\n",
    "            # wandb.log({\"Training Loss\": loss.item()})\n",
    "\n",
    "        #if _%500==0:\n",
    "            #print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # xm.optimizer_step(optimizer)\n",
    "        # xm.mark_step()\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lnHpp8HHXB0B"
   },
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, loader): #device\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(loader, 0):\n",
    "            # Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu\n",
    "            # => You need to add your data to the same device as your model.\n",
    "            y = data['target_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
    "            # DataParallel 일때 한 행동 1 : model 을 module 로 감싸주었음.\n",
    "            generated_ids = model.module.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length=150, \n",
    "                num_beams=2,\n",
    "                repetition_penalty=2.5, \n",
    "                length_penalty=1.0, \n",
    "                early_stopping=True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
    "            if _%100==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "    return predictions, actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): PegasusForConditionalGeneration(\n",
       "    (model): PegasusModel(\n",
       "      (shared): Embedding(96103, 1024, padding_idx=0)\n",
       "      (encoder): PegasusEncoder(\n",
       "        (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "        (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): PegasusEncoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): PegasusDecoder(\n",
       "        (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
       "        (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
       "        (layers): ModuleList(\n",
       "          (0): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (4): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (5): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (6): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (7): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (8): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (9): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (10): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (11): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (12): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (13): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (14): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (15): PegasusDecoderLayer(\n",
       "            (self_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (encoder_attn): PegasusAttention(\n",
       "              (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            )\n",
       "            (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
    "# Further this model is sent to device (GPU/TPU) for using the hardware.\n",
    "model = PegasusForConditionalGeneration.from_pretrained(model_name)\n",
    "model= torch.nn.DataParallel(model)\n",
    "model.to(device)\n",
    "# DataParallel 일때 한 행동 1 : 주석해제했음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'torch.cuda' from '/home/aiffelsummabot/anaconda3/envs/summabot/lib/python3.7/site-packages/torch/cuda/__init__.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch\n",
    "# torch.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "cuda\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# USE_CUDA = torch.cuda.is_available()\n",
    "# print(USE_CUDA)\n",
    "# print(torch.cuda.device_count())\n",
    "# print(device)\n",
    "# print(torch.cuda.current_device())\n",
    "# #if torch.cuda.device_count() > 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542,
     "referenced_widgets": [
      "b7783eba2ba44fbfad992e49c843c234",
      "39bdf3b783d44dc6ba9a8d6483743e0a",
      "2ad470db427045c1ae9d21ca1710317b",
      "f982f751923743d5946d93b10bcfddee",
      "64a50cf570374ce389d179aeb1a9464d",
      "e59c1ddb3c2344b09565c73f0bddb3e6",
      "87b7e432df3348f897e02de5f3f3acc9",
      "6718716068764237a00c09162ddb8f5b"
     ]
    },
    "executionInfo": {
     "elapsed": 9800,
     "status": "error",
     "timestamp": 1639208260424,
     "user": {
      "displayName": "김민순",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "03448037846432684882"
     },
     "user_tz": -540
    },
    "id": "KmAzMdS1mQhI",
    "outputId": "e5f44afa-f69d-4473-dd69-f4701c15a25a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msummabot\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/summabot/pegasus/runs/3h63l167\" target=\"_blank\">summer-river-45</a></strong> to <a href=\"https://wandb.ai/summabot/pegasus\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Full_Text  \\\n",
      "0  chief executive officer’s statement the berong...   \n",
      "1  chief executive officer’s statement the compan...   \n",
      "2  page 6 toledo mining corporation plc annual re...   \n",
      "3  review 2005 chief executive’s statement tomkin...   \n",
      "4  7 plc annual report and financial statements 2...   \n",
      "\n",
      "                                             Summary  \n",
      "0  the berong nickel mine has been in operation f...  \n",
      "1  berong nickel corporation is setting new stand...  \n",
      "2  toledo mining corporation plc reported a pre-t...  \n",
      "3  a key component of this is new product develop...  \n",
      "4  topps has seen its position as the uk’s number...  \n",
      "FULL Dataset: (10897, 2)\n",
      "TRAIN Dataset: (8717, 2)\n",
      "VALIDATION Dataset: (2180, 2)\n",
      "Initiating Fine-Tuning for the model on our dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "__floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0\n",
      "Completed 100\n",
      "Completed 200\n",
      "Completed 300\n",
      "Completed 400\n",
      "Completed 500\n",
      "Completed 600\n",
      "Completed 700\n",
      "Completed 800\n",
      "Completed 900\n",
      "Completed 1000\n",
      "Completed 1100\n",
      "Completed 1200\n",
      "Completed 1300\n",
      "Completed 1400\n",
      "Completed 1500\n",
      "Completed 1600\n",
      "Completed 1700\n",
      "Completed 1800\n",
      "Completed 1900\n",
      "Completed 2000\n",
      "Completed 2100\n",
      "Output Files generated for review\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9635... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 0.00MB of 0.00MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">summer-river-45</strong>: <a href=\"https://wandb.ai/summabot/pegasus/runs/3h63l167\" target=\"_blank\">https://wandb.ai/summabot/pegasus/runs/3h63l167</a><br/>\n",
       "Find logs at: <code>./wandb/run-20211212_145326-3h63l167/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    # WandB – Initialize a new run\n",
    "    wandb.init(project=wandb_project_name)\n",
    "\n",
    "    # WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "    # Defining some key variables that will be used later on in the training  \n",
    "    config = wandb.config          # Initialize config\n",
    "    config.TRAIN_BATCH_SIZE = 1    # input batch size for training (default: 64)\n",
    "    config.VALID_BATCH_SIZE = 1    # input batch size for testing (default: 1000)\n",
    "    config.TRAIN_EPOCHS = 5        # TO BE UPDATED. number of epochs to train (default: 10)\n",
    "    config.VAL_EPOCHS = 1 \n",
    "    config.LEARNING_RATE = 1e-4    # learning rate (default: 0.01)\n",
    "    config.SEED = 42               # random seed (default: 42)\n",
    "    config.MAX_LEN = 512\n",
    "    config.SUMMARY_LEN = 150 \n",
    "\n",
    "    # Set random seeds and deterministic pytorch for reproducibility\n",
    "    torch.manual_seed(config.SEED) # pytorch random seed\n",
    "    np.random.seed(config.SEED) # numpy random seed\n",
    "    torch.backends.cudnn.deterministic = True \n",
    "\n",
    "    model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
    "    tokenizer = PegasusTokenizer.from_pretrained(model_name) \n",
    "\n",
    "    # Importing and Pre-Processing the domain data\n",
    "    # Selecting the needed columns only. \n",
    "    # Adding the summarzie text in front of the text. \n",
    "    df = train_df3\n",
    "    df = df[['Full_Text','Summary']]\n",
    "    print(df.head())\n",
    "    \n",
    "    # Creation of Dataset and Dataloader\n",
    "    # Defining the train size. So 80% of the data will be used for training and the rest will be used for validation. \n",
    "    train_size = 0.8\n",
    "    split = int(train_size * df.shape[0])\n",
    "    #train_dataset=df.sample(frac=train_size,random_state = config.SEED)\n",
    "    train_dataset = df.iloc[:split]\n",
    "    val_dataset = df.iloc[split:]\n",
    "    val_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "    train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "    print(\"FULL Dataset: {}\".format(df.shape))\n",
    "    print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "    print(\"VALIDATION Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "\n",
    "    # Creating the Training and Validation dataset for further creation of Dataloader\n",
    "    training_set = CustomDataset(train_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "    val_set = CustomDataset(val_dataset, tokenizer, config.MAX_LEN, config.SUMMARY_LEN)\n",
    "\n",
    "    # Defining the parameters for creation of dataloaders\n",
    "    train_params = {\n",
    "        'batch_size': config.TRAIN_BATCH_SIZE,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    val_params = {\n",
    "        'batch_size': config.VALID_BATCH_SIZE,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 0\n",
    "        }\n",
    "\n",
    "    # Creation of Dataloaders for testing and validation. This will be used down for training and validation stage for the model.\n",
    "    training_loader = DataLoader(training_set, **train_params)\n",
    "    val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "    # model placeholder\n",
    "\n",
    "    # Defining the optimizer that will be used to tune the weights of the network in the training session. \n",
    "    optimizer = torch.optim.Adam(params =  model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "    # Log metrics with wandb\n",
    "    wandb.watch(model, log=\"all\")\n",
    "    # Training loop\n",
    "    print('Initiating Fine-Tuning for the model on our dataset')\n",
    "\n",
    "    for epoch in range(config.TRAIN_EPOCHS):\n",
    "    #    train(epoch, tokenizer, model, device, training_loader, optimizer)\n",
    "        fine_tuned_model = train(epoch, tokenizer, model, training_loader, optimizer) #device\n",
    "\n",
    "\n",
    "    # Validation loop and saving the resulting file with predictions and acutals in a dataframe.\n",
    "    # Saving the dataframe as predictions.csv\n",
    "    print('Now generating summaries on our fine tuned model for the validation dataset and saving it in a dataframe')\n",
    "    for epoch in range(config.VAL_EPOCHS):\n",
    "        predictions, actuals = validate(epoch, tokenizer, model, val_loader) # device\n",
    "        final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})\n",
    "        final_df.to_csv(predictions_filepath)\n",
    "        print('Output Files generated for review')\n",
    "    \n",
    "    wandb.finish()\n",
    "    return fine_tuned_model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    fine_tuned_model = main()\n",
    "    fine_tuned_model.module.save_pretrained(save_directory=save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0cJpxMoDpeBy"
   },
   "source": [
    "#### validation 데이터 prediction/label 비교 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "V7ZtmG3hpf2d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2180, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View a sample of the predictions data\n",
    "training_data = train_df3\n",
    "predictions_sample = pd.read_csv(predictions_filepath)\n",
    "predictions_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>we experienced a significant decline in sales ...</td>\n",
       "      <td>spirax sarco is well spread geographically, ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Company’s performance in 2007 was driven by si...</td>\n",
       "      <td>spi achieved many of its goals in 2007 and par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>watson-marlow achieved solid organic sales gro...</td>\n",
       "      <td>r d in the steam specialties business grew 4 p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Free cash ow down by only pound 4.0 million de...</td>\n",
       "      <td>spirent communications was named 2002 market e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>spirent releases over 50 new products and addi...</td>\n",
       "      <td>spirent communications plc annual report 2010 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                     Generated Text  \\\n",
       "0           0  we experienced a significant decline in sales ...   \n",
       "1           1  Company’s performance in 2007 was driven by si...   \n",
       "2           2  watson-marlow achieved solid organic sales gro...   \n",
       "3           3  Free cash ow down by only pound 4.0 million de...   \n",
       "4           4  spirent releases over 50 new products and addi...   \n",
       "\n",
       "                                         Actual Text  \n",
       "0  spirax sarco is well spread geographically, ac...  \n",
       "1  spi achieved many of its goals in 2007 and par...  \n",
       "2  r d in the steam specialties business grew 4 p...  \n",
       "3  spirent communications was named 2002 market e...  \n",
       "4  spirent communications plc annual report 2010 ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>FT_Len</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8717</th>\n",
       "      <td>14636_765083_2</td>\n",
       "      <td>and trained sales engineers . as a result , we...</td>\n",
       "      <td>500.0</td>\n",
       "      <td>spirax sarco is well spread geographically, ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Original_Filename                                          Full_Text  \\\n",
       "8717    14636_765083_2  and trained sales engineers . as a result , we...   \n",
       "\n",
       "      FT_Len                                            Summary  \n",
       "8717   500.0  spirax sarco is well spread geographically, ac...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3.loc[train_df3['Summary'] == predictions_sample['Actual Text'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "jeMTiuwaplBS"
   },
   "outputs": [],
   "source": [
    "# def shap_summary_values(model, tokenizer, text):\n",
    "#     text_list = []\n",
    "#     text_list.append(text)\n",
    "#     explainer = shap.Explainer(model, tokenizer)\n",
    "#     shap_values = explainer(text_list)\n",
    "#     display(shap.plots.text(shap_values))\n",
    "#     return\n",
    "\n",
    "def view_summary_comparisons(i, predictions_sample=predictions_sample):\n",
    "    summary1 = predictions_sample[\"Generated Text\"].iloc[i]\n",
    "    print(\"predictions: \", summary1, '\\n')\n",
    "    print(\"predictions 단어길이: \", len(predictions_sample[\"Generated Text\"].iloc[i].split()), '\\n')\n",
    "    summary2 = predictions_sample[\"Actual Text\"].iloc[i]\n",
    "    print(\"label: \", summary2, '\\n')\n",
    "    print(\"label 단어길이: \", len(predictions_sample[\"Actual Text\"].iloc[i].split()))\n",
    "    return\n",
    "\n",
    "def get_training_data(i, tokens, training_data=training_data):\n",
    "    print(training_data.loc[i])\n",
    "    print(training_data.loc[i, \"Full_Text\"])\n",
    "    print(\"\\n\")\n",
    "    len(training_data.loc[i, \"Full_Text\"].split())\n",
    "    print(\"\\n\")\n",
    "    text = ' '.join(training_data.loc[i, \"Full_Text\"].split()[0:tokens])\n",
    "    print(\"\\n\")\n",
    "    len(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wy--cZMfppwd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PegasusForConditionalGeneration(\n",
      "  (model): PegasusModel(\n",
      "    (shared): Embedding(96103, 1024, padding_idx=0)\n",
      "    (encoder): PegasusEncoder(\n",
      "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
      "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (12): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (13): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (14): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (15): PegasusEncoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): PegasusDecoder(\n",
      "      (embed_tokens): Embedding(96103, 1024, padding_idx=0)\n",
      "      (embed_positions): PegasusSinusoidalPositionalEmbedding(512, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (2): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (3): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (4): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (5): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (6): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (7): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (8): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (9): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (10): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (11): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (12): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (13): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (14): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (15): PegasusDecoderLayer(\n",
      "          (self_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): PegasusAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "fine_tuned_model = PegasusForConditionalGeneration.from_pretrained(save_directory)#.to(device)\n",
    "model_name = \"human-centered-summarization/financial-summarization-pegasus\"\n",
    "tokenizer = PegasusTokenizer.from_pretrained(model_name) \n",
    "print(fine_tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OMapABTCWqVY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions:  we experienced a significant decline in sales volume during the year as a result of the global economic recession. \n",
      "\n",
      "predictions 단어길이:  19 \n",
      "\n",
      "label:  spirax sarco is well spread geographically, across the product range and over a diverse range of industries. our business strategy remains focused on achieving long-term, steady and profitable sales growth. \n",
      "\n",
      "label 단어길이:  30\n",
      "Original_Filename                                       14636_765083_2\n",
      "Full_Text            and trained sales engineers . as a result , we...\n",
      "FT_Len                                                           500.0\n",
      "Summary              spirax sarco is well spread geographically, ac...\n",
      "Name: 8717, dtype: object\n",
      "and trained sales engineers . as a result , we reduced our workforce by 7 percent through the year , most of which came as part of an announced 5 percent headcount reduction in early 2009, with the balance coming from natural attrition throughout the year . most of the headcount reductions were in back-office support functions and manufacturing . additionally , our local operating company management teams were vigilant in controlling other operating costs . the announced general headcount reduction was the first ever for spirax sarco indicative of the unprecedented global economic downturn but it was managed effectively by our management teams around the world . we took steps to size our manufacturing operation in cheltenham , not only for the decline in volume resulting from the global economic recession but also in anticipation of the volume transfer to our new manufacturing plant in china . additionally , we recently announced a reduction in our manufacturing footprint at ch tellerault , france , also in line with our global manufacturing strategy . we continued to invest in key growth programmes for the future . in china , we selectively added sales people for the steam business . we also invested in our watson-marlow business to continue developing new markets , adding sales people in russia and mexico . we believe that our sales teams are well positioned to handle the eventual rebound in our end markets . also , we increased the amount of direct r d investment , virtually the only area of the business that was allowed increased expenditure . new product development is a key activity that will drive longer-term growth and therefore we have continued to invest through the downturn . we have also sustained capital expenditure at a high level in the year as we invest in delivering our manufacturing strategy . what are the key business drivers and trends ? our business is well spread geographically , across the product range and over a diverse range of industries . the following key factors have the primary influence on the underlying demand in our markets global economic growth . industrial production and investment . capacity utilisation . energy costs . increasing customer outsourcing of design and maintenance . regulatory legislation eg , emissions , hygienic standards , plant safety . looking ahead how do you plan to take the business forward ? our business strategy remains focused on achieving long-term , steady and profitable sales growth . the industrial and commercial steam-using market is highly fragmented and although spirax sarco is the market leader , we still have significant growth opportunities . it is not our products alone that provide the value to our customers it is the application of our extensive knowledge . 8 spirax-sarco engineering plc annual report and accounts 2009 increasing watson-marlow’s capability in offering high purity ... particularly in the biopharm sector . an interview with mark vernon continued chief executive officer sharpening our edge by investing in our\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "view_summary_comparisons(0)\n",
    "text1 = get_training_data(8717, tokens=200, training_data=training_data)\n",
    "# both predictions and label are too short and did not caputre all content in full text. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가하기 \n",
    "test 데이터 중에서 처음 100개를 finetuned된 모델에 넣어서 prediction을 생성시키고 label과의 rouge score를 계산해서 Longformer fine tuned  모델에서 나온 prediction과 비교했다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>sen_500</th>\n",
       "      <th>sen_1000</th>\n",
       "      <th>sen_1500</th>\n",
       "      <th>sen_2000</th>\n",
       "      <th>sen_2500</th>\n",
       "      <th>sen_3000</th>\n",
       "      <th>sen_3500</th>\n",
       "      <th>sen_4000</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30777_904926_2</td>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ....</td>\n",
       "      <td>business saw growth of 14 percent with the maj...</td>\n",
       "      <td>. strategic progress the group’s strategy enco...</td>\n",
       "      <td>from contract wins on automotive and aerospace...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ...</td>\n",
       "      <td>harris group chief executive overview bodycote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30783_905079_2</td>\n",
       "      <td>strategic report chief executive’s statement 1...</td>\n",
       "      <td>to manage and report on these exposures more e...</td>\n",
       "      <td>stage in its journey . your commitment and vis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>strategic report chief executive’s statement ...</td>\n",
       "      <td>alpha grew its client base by 39 percent in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30785_905133_2</td>\n",
       "      <td>summary our dedication to providing our client...</td>\n",
       "      <td>the last two years . this is due to a number o...</td>\n",
       "      <td>see interest from local authorities to procure...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>summary our dedication to providing our clien...</td>\n",
       "      <td>mears group plc annual report and accounts 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30785_905134_2</td>\n",
       "      <td>q a with ceo , david miles 92 percent of tenan...</td>\n",
       "      <td>an area where we can afford to stand still and...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>q a with ceo , david miles 92 percent of tena...</td>\n",
       "      <td>q a with ceo, david miles 92 percent of tenant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30813_906032_2</td>\n",
       "      <td>strategic report domino’s pizza group plc annu...</td>\n",
       "      <td>accounts 2017 domino’s pizza group plc 09 whil...</td>\n",
       "      <td>, cooks your pizza fresh in a local store , an...</td>\n",
       "      <td>visibility of the brand , improve customer ser...</td>\n",
       "      <td>expect to complete roll-out by q3 of 2018. a f...</td>\n",
       "      <td>economy and by our own actions , particularly ...</td>\n",
       "      <td>achieves weekly unit sales of over pound 37,00...</td>\n",
       "      <td>ticket size to absorb the cost of delivery . w...</td>\n",
       "      <td>strategic report domino’s pizza group plc ann...</td>\n",
       "      <td>domino’s pizza group plc annual report account...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original_Filename                                            sen_500  \\\n",
       "0    30777_904926_2  25695 19 march 2018 3 29 pm proof 7 02 s . c ....   \n",
       "1    30783_905079_2  strategic report chief executive’s statement 1...   \n",
       "2    30785_905133_2  summary our dedication to providing our client...   \n",
       "3    30785_905134_2  q a with ceo , david miles 92 percent of tenan...   \n",
       "4    30813_906032_2  strategic report domino’s pizza group plc annu...   \n",
       "\n",
       "                                            sen_1000  \\\n",
       "0  business saw growth of 14 percent with the maj...   \n",
       "1  to manage and report on these exposures more e...   \n",
       "2  the last two years . this is due to a number o...   \n",
       "3  an area where we can afford to stand still and...   \n",
       "4  accounts 2017 domino’s pizza group plc 09 whil...   \n",
       "\n",
       "                                            sen_1500  \\\n",
       "0  . strategic progress the group’s strategy enco...   \n",
       "1  stage in its journey . your commitment and vis...   \n",
       "2  see interest from local authorities to procure...   \n",
       "3                                                NaN   \n",
       "4  , cooks your pizza fresh in a local store , an...   \n",
       "\n",
       "                                            sen_2000  \\\n",
       "0  from contract wins on automotive and aerospace...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  visibility of the brand , improve customer ser...   \n",
       "\n",
       "                                            sen_2500  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  expect to complete roll-out by q3 of 2018. a f...   \n",
       "\n",
       "                                            sen_3000  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  economy and by our own actions , particularly ...   \n",
       "\n",
       "                                            sen_3500  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  achieves weekly unit sales of over pound 37,00...   \n",
       "\n",
       "                                            sen_4000  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  ticket size to absorb the cost of delivery . w...   \n",
       "\n",
       "                                           Full_Text  \\\n",
       "0   25695 19 march 2018 3 29 pm proof 7 02 s . c ...   \n",
       "1   strategic report chief executive’s statement ...   \n",
       "2   summary our dedication to providing our clien...   \n",
       "3   q a with ceo , david miles 92 percent of tena...   \n",
       "4   strategic report domino’s pizza group plc ann...   \n",
       "\n",
       "                                             Summary  \n",
       "0  harris group chief executive overview bodycote...  \n",
       "1  alpha grew its client base by 39 percent in th...  \n",
       "2  mears group plc annual report and accounts 201...  \n",
       "3  q a with ceo, david miles 92 percent of tenant...  \n",
       "4  domino’s pizza group plc annual report account...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv('test_data_final.csv', index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>sen_500</th>\n",
       "      <th>sen_1000</th>\n",
       "      <th>sen_1500</th>\n",
       "      <th>sen_2000</th>\n",
       "      <th>sen_2500</th>\n",
       "      <th>sen_3000</th>\n",
       "      <th>sen_3500</th>\n",
       "      <th>sen_4000</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>296</td>\n",
       "      <td>237</td>\n",
       "      <td>157</td>\n",
       "      <td>98</td>\n",
       "      <td>61</td>\n",
       "      <td>30</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "      <td>296</td>\n",
       "      <td>237</td>\n",
       "      <td>157</td>\n",
       "      <td>98</td>\n",
       "      <td>61</td>\n",
       "      <td>30</td>\n",
       "      <td>328</td>\n",
       "      <td>328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>31013_912266_2</td>\n",
       "      <td>meggitt plc f inanc ial statement s annual rep...</td>\n",
       "      <td>those projects best aligned with its capabilit...</td>\n",
       "      <td>promising order book in each division . tyman ...</td>\n",
       "      <td>of the 2014 peak , but expected to increase wi...</td>\n",
       "      <td>businesses into three focused units will enabl...</td>\n",
       "      <td>increasingly attractive and we are well positi...</td>\n",
       "      <td>. if your customers prefer your place then you...</td>\n",
       "      <td>in mexico , we expect to return to customer gr...</td>\n",
       "      <td>chief executive’s statement capitalise on exi...</td>\n",
       "      <td>chief executive officer’s strategic report fy1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Original_Filename                                            sen_500  \\\n",
       "count                328                                                328   \n",
       "unique               328                                                328   \n",
       "top       31013_912266_2  meggitt plc f inanc ial statement s annual rep...   \n",
       "freq                   1                                                  1   \n",
       "\n",
       "                                                 sen_1000  \\\n",
       "count                                                 328   \n",
       "unique                                                328   \n",
       "top     those projects best aligned with its capabilit...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 sen_1500  \\\n",
       "count                                                 296   \n",
       "unique                                                296   \n",
       "top     promising order book in each division . tyman ...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 sen_2000  \\\n",
       "count                                                 237   \n",
       "unique                                                237   \n",
       "top     of the 2014 peak , but expected to increase wi...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 sen_2500  \\\n",
       "count                                                 157   \n",
       "unique                                                157   \n",
       "top     businesses into three focused units will enabl...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 sen_3000  \\\n",
       "count                                                  98   \n",
       "unique                                                 98   \n",
       "top     increasingly attractive and we are well positi...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 sen_3500  \\\n",
       "count                                                  61   \n",
       "unique                                                 61   \n",
       "top     . if your customers prefer your place then you...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                 sen_4000  \\\n",
       "count                                                  30   \n",
       "unique                                                 30   \n",
       "top     in mexico , we expect to return to customer gr...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                Full_Text  \\\n",
       "count                                                 328   \n",
       "unique                                                328   \n",
       "top      chief executive’s statement capitalise on exi...   \n",
       "freq                                                    1   \n",
       "\n",
       "                                                  Summary  \n",
       "count                                                 328  \n",
       "unique                                                328  \n",
       "top     chief executive officer’s strategic report fy1...  \n",
       "freq                                                    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.fillna('', inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    }
   ],
   "source": [
    "test_df1 = test_df[:100].copy()\n",
    "test_df2 = test_df[100:200].copy()\n",
    "test_df3 = test_df[200:].copy()\n",
    "print(len(test_df1) + len(test_df2) + len(test_df3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)): \n",
    "    df.loc[i, 'prediction'] = ''\n",
    "\n",
    "    for c in range(1,9):\n",
    "        sec_summary = ''\n",
    "        source_doc = tokenizer(text=df.iloc[i, c], \n",
    "                              max_length=512, \n",
    "                              padding=True, \n",
    "                              return_tensors=\"pt\",\n",
    "                              truncation=True)\n",
    "\n",
    "        sam_input_ids = source_doc['input_ids']\n",
    "        sam_mask = source_doc['attention_mask']\n",
    "\n",
    "        generated_ids = fine_tuned_model.generate(\n",
    "            input_ids = sam_input_ids,\n",
    "            attention_mask = sam_mask, \n",
    "            max_length=150, \n",
    "            num_beams=5,\n",
    "            repetition_penalty=2.5, \n",
    "            length_penalty=1.0, \n",
    "            early_stopping=True\n",
    "        )\n",
    "\n",
    "        for g in generated_ids:\n",
    "            preds = tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) \n",
    "            sec_summary += preds\n",
    "\n",
    "        df.loc[i, 'prediction'] += sec_summary\n",
    "\n",
    "return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original_Filename</th>\n",
       "      <th>sen_500</th>\n",
       "      <th>sen_1000</th>\n",
       "      <th>sen_1500</th>\n",
       "      <th>sen_2000</th>\n",
       "      <th>sen_2500</th>\n",
       "      <th>sen_3000</th>\n",
       "      <th>sen_3500</th>\n",
       "      <th>sen_4000</th>\n",
       "      <th>Full_Text</th>\n",
       "      <th>Summary</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30777_904926_2</td>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ....</td>\n",
       "      <td>business saw growth of 14 percent with the maj...</td>\n",
       "      <td>. strategic progress the group’s strategy enco...</td>\n",
       "      <td>from contract wins on automotive and aerospace...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>25695 19 march 2018 3 29 pm proof 7 02 s . c ...</td>\n",
       "      <td>harris group chief executive overview bodycote...</td>\n",
       "      <td>Return on sales increased to 18.0 percent from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30783_905079_2</td>\n",
       "      <td>strategic report chief executive’s statement 1...</td>\n",
       "      <td>to manage and report on these exposures more e...</td>\n",
       "      <td>stage in its journey . your commitment and vis...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>strategic report chief executive’s statement ...</td>\n",
       "      <td>alpha grew its client base by 39 percent in th...</td>\n",
       "      <td>Strategic report chief executive’s statement 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30785_905133_2</td>\n",
       "      <td>summary our dedication to providing our client...</td>\n",
       "      <td>the last two years . this is due to a number o...</td>\n",
       "      <td>see interest from local authorities to procure...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>summary our dedication to providing our clien...</td>\n",
       "      <td>mears group plc annual report and accounts 201...</td>\n",
       "      <td>Annual report and accounts 2017 chief executiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30785_905134_2</td>\n",
       "      <td>q a with ceo , david miles 92 percent of tenan...</td>\n",
       "      <td>an area where we can afford to stand still and...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>q a with ceo , david miles 92 percent of tena...</td>\n",
       "      <td>q a with ceo, david miles 92 percent of tenant...</td>\n",
       "      <td>Care division returned to profitability in 201...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30813_906032_2</td>\n",
       "      <td>strategic report domino’s pizza group plc annu...</td>\n",
       "      <td>accounts 2017 domino’s pizza group plc 09 whil...</td>\n",
       "      <td>, cooks your pizza fresh in a local store , an...</td>\n",
       "      <td>visibility of the brand , improve customer ser...</td>\n",
       "      <td>expect to complete roll-out by q3 of 2018. a f...</td>\n",
       "      <td>economy and by our own actions , particularly ...</td>\n",
       "      <td>achieves weekly unit sales of over pound 37,00...</td>\n",
       "      <td>ticket size to absorb the cost of delivery . w...</td>\n",
       "      <td>strategic report domino’s pizza group plc ann...</td>\n",
       "      <td>domino’s pizza group plc annual report account...</td>\n",
       "      <td>System sales were up 8.6 percent on a 52 week ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Original_Filename                                            sen_500  \\\n",
       "0    30777_904926_2  25695 19 march 2018 3 29 pm proof 7 02 s . c ....   \n",
       "1    30783_905079_2  strategic report chief executive’s statement 1...   \n",
       "2    30785_905133_2  summary our dedication to providing our client...   \n",
       "3    30785_905134_2  q a with ceo , david miles 92 percent of tenan...   \n",
       "4    30813_906032_2  strategic report domino’s pizza group plc annu...   \n",
       "\n",
       "                                            sen_1000  \\\n",
       "0  business saw growth of 14 percent with the maj...   \n",
       "1  to manage and report on these exposures more e...   \n",
       "2  the last two years . this is due to a number o...   \n",
       "3  an area where we can afford to stand still and...   \n",
       "4  accounts 2017 domino’s pizza group plc 09 whil...   \n",
       "\n",
       "                                            sen_1500  \\\n",
       "0  . strategic progress the group’s strategy enco...   \n",
       "1  stage in its journey . your commitment and vis...   \n",
       "2  see interest from local authorities to procure...   \n",
       "3                                                      \n",
       "4  , cooks your pizza fresh in a local store , an...   \n",
       "\n",
       "                                            sen_2000  \\\n",
       "0  from contract wins on automotive and aerospace...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  visibility of the brand , improve customer ser...   \n",
       "\n",
       "                                            sen_2500  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  expect to complete roll-out by q3 of 2018. a f...   \n",
       "\n",
       "                                            sen_3000  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  economy and by our own actions , particularly ...   \n",
       "\n",
       "                                            sen_3500  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  achieves weekly unit sales of over pound 37,00...   \n",
       "\n",
       "                                            sen_4000  \\\n",
       "0                                                      \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  ticket size to absorb the cost of delivery . w...   \n",
       "\n",
       "                                           Full_Text  \\\n",
       "0   25695 19 march 2018 3 29 pm proof 7 02 s . c ...   \n",
       "1   strategic report chief executive’s statement ...   \n",
       "2   summary our dedication to providing our clien...   \n",
       "3   q a with ceo , david miles 92 percent of tena...   \n",
       "4   strategic report domino’s pizza group plc ann...   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  harris group chief executive overview bodycote...   \n",
       "1  alpha grew its client base by 39 percent in th...   \n",
       "2  mears group plc annual report and accounts 201...   \n",
       "3  q a with ceo, david miles 92 percent of tenant...   \n",
       "4  domino’s pizza group plc annual report account...   \n",
       "\n",
       "                                          prediction  \n",
       "0  Return on sales increased to 18.0 percent from...  \n",
       "1  Strategic report chief executive’s statement 1...  \n",
       "2  Annual report and accounts 2017 chief executiv...  \n",
       "3  Care division returned to profitability in 201...  \n",
       "4  System sales were up 8.6 percent on a 52 week ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full text 길이:  1178\n",
      "label 길이:  111\n",
      "pegasus prediction 길이:  85\n"
     ]
    }
   ],
   "source": [
    "print(\"full text 길이: \", len(test_df1.loc[1, 'Full_Text'].split()))\n",
    "print(\"label 길이: \", len(test_df1.loc[1, 'Summary'].split()))\n",
    "print(\"pegasus prediction 길이: \", len(test_df1.loc[1, 'prediction'].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df1.to_csv('/home/aiffelsummabot/Pegasus/test_predictions/pegasus_predictions_part1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0PcSn7RdQc4s"
   },
   "outputs": [],
   "source": [
    "# Rouge Score Calculation\n",
    "def rouge_scores(gen_summary_list, actual_summary_list, metric='fmeasure'):\n",
    "    rouge1_scores = []\n",
    "    rougeL_scores = []\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "    for i in range(0, len(gen_summary_list)):\n",
    "        scores = scorer.score(actual_summary_list[i], gen_summary_list[i])\n",
    "        if metric == 'recall':\n",
    "            rouge1_scores.append(scores['rouge1'][1])\n",
    "            rougeL_scores.append(scores['rougeL'][1])\n",
    "        elif metric == 'precision':\n",
    "            rouge1_scores.append(scores['rouge1'][0])\n",
    "            rougeL_scores.append(scores['rougeL'][0])\n",
    "        elif metric == 'fmeasure':\n",
    "            rouge1_scores.append(scores['rouge1'][2])\n",
    "            rougeL_scores.append(scores['rougeL'][2])     \n",
    "    print(\"Average Rouge-1\", str(metric), \":\", round(np.mean(rouge1_scores), 2))\n",
    "    print(\"Average Rouge-L\", str(metric), \":\", round(np.mean(rougeL_scores), 2))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Rouge-1 fmeasure : 0.34\n",
      "Average Rouge-L fmeasure : 0.21\n"
     ]
    }
   ],
   "source": [
    "print(\"test 데이터 100까지 f-measure score\")\n",
    "rouge_scores(test_df1['prediction'], test_df1['Summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Pegasus.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2ad470db427045c1ae9d21ca1710317b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e59c1ddb3c2344b09565c73f0bddb3e6",
      "placeholder": "​",
      "style": "IPY_MODEL_64a50cf570374ce389d179aeb1a9464d",
      "value": " 0.01MB of 0.01MB uploaded (0.00MB deduped)\r"
     }
    },
    "39bdf3b783d44dc6ba9a8d6483743e0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "64a50cf570374ce389d179aeb1a9464d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6718716068764237a00c09162ddb8f5b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "87b7e432df3348f897e02de5f3f3acc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7783eba2ba44fbfad992e49c843c234": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2ad470db427045c1ae9d21ca1710317b",
       "IPY_MODEL_f982f751923743d5946d93b10bcfddee"
      ],
      "layout": "IPY_MODEL_39bdf3b783d44dc6ba9a8d6483743e0a"
     }
    },
    "e59c1ddb3c2344b09565c73f0bddb3e6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f982f751923743d5946d93b10bcfddee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6718716068764237a00c09162ddb8f5b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_87b7e432df3348f897e02de5f3f3acc9",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
